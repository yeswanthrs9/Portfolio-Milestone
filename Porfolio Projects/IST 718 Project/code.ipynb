{"cells":[{"cell_type":"markdown","source":["## Big Data Analytics Project"],"metadata":{}},{"cell_type":"markdown","source":["### Group 7"],"metadata":{}},{"cell_type":"markdown","source":["##### Authors: Akshay Pradeep Bhala,  Juilee Prashant Salunkhe, Sai Praharsha Devalla, Yeswanth Reddy Velapalem"],"metadata":{}},{"cell_type":"markdown","source":["### Introduction:\nSubject area is Social media Marketing and Content optimization.\n<br>\nAbout Data: <br>\nEvery online platform is striving to publish the articles on their site which have great value and bring most shares. In this project, we do the prediction of shares of an article based on the data produced by ‘Mashable’ where they collected data of around 39000 articles. Intend to help Mashable to decide which articles should they publish because they can actually predict which articles will be having the maximum number of shares. \nProject aims to do the following:\n1. Descriptive analytics to further understand patterns, trends, and anomalies in data.\n2. To understand and analysethe data and use neural-networks to classify the articles into different categories.\n3. Binary classification as popular vs unpopular using a decision threshold of 1400 social interactions.the class value (shares) is continuously valued. We transformed the task into a binary task using a decision threshold of 1400.\n4. Experiments with different models: Random Forest (best model),Adaboost, SVM, KNN and Naïve Bayes\n5. Evaluate the performance of various models and select best two models for tuning process."],"metadata":{}},{"cell_type":"code","source":["# Do not delete or change this cell\n\nimport os\n\n# Define a function to determine if we are running on data bricks\n# Return true if running in the data bricks environment, false otherwise\ndef is_databricks():\n    # get the databricks runtime version\n    db_env = os.getenv(\"DATABRICKS_RUNTIME_VERSION\")\n    \n    # if running on data bricks\n    if db_env != None:\n        return True\n    else:\n        return False\n\n# Define a function to read the data file.  The full path data file name is constructed\n# by checking runtime environment variables to determine if the runtime environment is \n# databricks, or a student's personal computer.  The full path file name is then\n# constructed based on the runtime env.\n# \n# Params\n#   data_file_name: The base name of the data file to load\n# \n# Returns the full path file name based on the runtime env\n#\ndef get_training_filename(data_file_name):    \n    # if running on data bricks\n    if is_databricks():\n        # build the full path file name assuming data brick env\n        full_path_name = \"/FileStore/tables/%s\" % data_file_name\n    # else the data is assumed to be in the same dir as this notebook\n    else:\n        # Assume the student is running on their own computer and load the data\n        # file from the same dir as this notebook\n        full_path_name = data_file_name\n    \n    # return the full path file name to the caller\n    return full_path_name"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["##### *Importing all the necessary libraries*"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import functions as fn\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import Row\nfrom pyspark.ml import feature\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml import regression\nfrom pyspark.ml import classification\nfrom math import exp,fabs\nfrom pyspark.ml.feature import StandardScaler\nimport re \nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import IntegerType,DoubleType\nfrom pyspark.ml import feature, regression, evaluation, Pipeline\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\nfrom pyspark.ml import Pipeline\nfrom sklearn.metrics import roc_curve\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator,RegressionEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pyspark.sql.functions import when\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sb\nsb.set_palette('pastel')\n\nspark = SparkSession.builder.getOrCreate()\nsc = spark.sparkContext"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["##### *Loading the data*"],"metadata":{}},{"cell_type":"code","source":["pop_df = spark.read.csv(get_training_filename('OnlineNewsPopularity.csv'), header=True, inferSchema=True)\nprint(f\"No of rows and columns in spam_df:({pop_df.count()},{len(pop_df.columns)})\")\npop_df.toPandas().head(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>timedelta</th>\n      <th>n_tokens_title</th>\n      <th>n_tokens_content</th>\n      <th>n_unique_tokens</th>\n      <th>n_non_stop_words</th>\n      <th>n_non_stop_unique_tokens</th>\n      <th>num_hrefs</th>\n      <th>num_self_hrefs</th>\n      <th>num_imgs</th>\n      <th>num_videos</th>\n      <th>average_token_length</th>\n      <th>num_keywords</th>\n      <th>data_channel_is_lifestyle</th>\n      <th>data_channel_is_entertainment</th>\n      <th>data_channel_is_bus</th>\n      <th>data_channel_is_socmed</th>\n      <th>data_channel_is_tech</th>\n      <th>data_channel_is_world</th>\n      <th>kw_min_min</th>\n      <th>kw_max_min</th>\n      <th>kw_avg_min</th>\n      <th>kw_min_max</th>\n      <th>kw_max_max</th>\n      <th>kw_avg_max</th>\n      <th>kw_min_avg</th>\n      <th>kw_max_avg</th>\n      <th>kw_avg_avg</th>\n      <th>self_reference_min_shares</th>\n      <th>self_reference_max_shares</th>\n      <th>self_reference_avg_sharess</th>\n      <th>weekday_is_monday</th>\n      <th>weekday_is_tuesday</th>\n      <th>weekday_is_wednesday</th>\n      <th>weekday_is_thursday</th>\n      <th>weekday_is_friday</th>\n      <th>weekday_is_saturday</th>\n      <th>weekday_is_sunday</th>\n      <th>is_weekend</th>\n      <th>LDA_00</th>\n      <th>LDA_01</th>\n      <th>LDA_02</th>\n      <th>LDA_03</th>\n      <th>LDA_04</th>\n      <th>global_subjectivity</th>\n      <th>global_sentiment_polarity</th>\n      <th>global_rate_positive_words</th>\n      <th>global_rate_negative_words</th>\n      <th>rate_positive_words</th>\n      <th>rate_negative_words</th>\n      <th>avg_positive_polarity</th>\n      <th>min_positive_polarity</th>\n      <th>max_positive_polarity</th>\n      <th>avg_negative_polarity</th>\n      <th>min_negative_polarity</th>\n      <th>max_negative_polarity</th>\n      <th>title_subjectivity</th>\n      <th>title_sentiment_polarity</th>\n      <th>abs_title_subjectivity</th>\n      <th>abs_title_sentiment_polarity</th>\n      <th>shares</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n      <td>731.0</td>\n      <td>12.0</td>\n      <td>219.0</td>\n      <td>0.663594</td>\n      <td>1.0</td>\n      <td>0.815385</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.680365</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>496.0</td>\n      <td>496.0</td>\n      <td>496.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.500331</td>\n      <td>0.378279</td>\n      <td>0.040005</td>\n      <td>0.041263</td>\n      <td>0.040123</td>\n      <td>0.521617</td>\n      <td>0.092562</td>\n      <td>0.045662</td>\n      <td>0.013699</td>\n      <td>0.769231</td>\n      <td>0.230769</td>\n      <td>0.378636</td>\n      <td>0.100000</td>\n      <td>0.7</td>\n      <td>-0.350000</td>\n      <td>-0.600</td>\n      <td>-0.200000</td>\n      <td>0.500000</td>\n      <td>-0.187500</td>\n      <td>0.000000</td>\n      <td>0.187500</td>\n      <td>593.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n      <td>731.0</td>\n      <td>9.0</td>\n      <td>255.0</td>\n      <td>0.604743</td>\n      <td>1.0</td>\n      <td>0.791946</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.913725</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.799756</td>\n      <td>0.050047</td>\n      <td>0.050096</td>\n      <td>0.050101</td>\n      <td>0.050001</td>\n      <td>0.341246</td>\n      <td>0.148948</td>\n      <td>0.043137</td>\n      <td>0.015686</td>\n      <td>0.733333</td>\n      <td>0.266667</td>\n      <td>0.286915</td>\n      <td>0.033333</td>\n      <td>0.7</td>\n      <td>-0.118750</td>\n      <td>-0.125</td>\n      <td>-0.100000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>711.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n      <td>731.0</td>\n      <td>9.0</td>\n      <td>211.0</td>\n      <td>0.575130</td>\n      <td>1.0</td>\n      <td>0.663866</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.393365</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>918.0</td>\n      <td>918.0</td>\n      <td>918.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.217792</td>\n      <td>0.033334</td>\n      <td>0.033351</td>\n      <td>0.033334</td>\n      <td>0.682188</td>\n      <td>0.702222</td>\n      <td>0.323333</td>\n      <td>0.056872</td>\n      <td>0.009479</td>\n      <td>0.857143</td>\n      <td>0.142857</td>\n      <td>0.495833</td>\n      <td>0.100000</td>\n      <td>1.0</td>\n      <td>-0.466667</td>\n      <td>-0.800</td>\n      <td>-0.133333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1500.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n      <td>731.0</td>\n      <td>9.0</td>\n      <td>531.0</td>\n      <td>0.503788</td>\n      <td>1.0</td>\n      <td>0.665635</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.404896</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.028573</td>\n      <td>0.419300</td>\n      <td>0.494651</td>\n      <td>0.028905</td>\n      <td>0.028572</td>\n      <td>0.429850</td>\n      <td>0.100705</td>\n      <td>0.041431</td>\n      <td>0.020716</td>\n      <td>0.666667</td>\n      <td>0.333333</td>\n      <td>0.385965</td>\n      <td>0.136364</td>\n      <td>0.8</td>\n      <td>-0.369697</td>\n      <td>-0.600</td>\n      <td>-0.166667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1200.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n      <td>731.0</td>\n      <td>13.0</td>\n      <td>1072.0</td>\n      <td>0.415646</td>\n      <td>1.0</td>\n      <td>0.540890</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>4.682836</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>545.0</td>\n      <td>16000.0</td>\n      <td>3151.157895</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.028633</td>\n      <td>0.028794</td>\n      <td>0.028575</td>\n      <td>0.028572</td>\n      <td>0.885427</td>\n      <td>0.513502</td>\n      <td>0.281003</td>\n      <td>0.074627</td>\n      <td>0.012127</td>\n      <td>0.860215</td>\n      <td>0.139785</td>\n      <td>0.411127</td>\n      <td>0.033333</td>\n      <td>1.0</td>\n      <td>-0.220192</td>\n      <td>-0.500</td>\n      <td>-0.050000</td>\n      <td>0.454545</td>\n      <td>0.136364</td>\n      <td>0.045455</td>\n      <td>0.136364</td>\n      <td>505.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["##### *Checking for the NaN and duplicate records*"],"metadata":{}},{"cell_type":"code","source":["#Checking for nan values\nfrom pyspark.sql.functions import isnan, when, count, col\npop_df.select([count(when(isnan(c), c)).alias(c) for c in pop_df.columns]).toPandas().head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>timedelta</th>\n      <th>n_tokens_title</th>\n      <th>n_tokens_content</th>\n      <th>n_unique_tokens</th>\n      <th>n_non_stop_words</th>\n      <th>n_non_stop_unique_tokens</th>\n      <th>num_hrefs</th>\n      <th>num_self_hrefs</th>\n      <th>num_imgs</th>\n      <th>num_videos</th>\n      <th>average_token_length</th>\n      <th>num_keywords</th>\n      <th>data_channel_is_lifestyle</th>\n      <th>data_channel_is_entertainment</th>\n      <th>data_channel_is_bus</th>\n      <th>data_channel_is_socmed</th>\n      <th>data_channel_is_tech</th>\n      <th>data_channel_is_world</th>\n      <th>kw_min_min</th>\n      <th>kw_max_min</th>\n      <th>kw_avg_min</th>\n      <th>kw_min_max</th>\n      <th>kw_max_max</th>\n      <th>kw_avg_max</th>\n      <th>kw_min_avg</th>\n      <th>kw_max_avg</th>\n      <th>kw_avg_avg</th>\n      <th>self_reference_min_shares</th>\n      <th>self_reference_max_shares</th>\n      <th>self_reference_avg_sharess</th>\n      <th>weekday_is_monday</th>\n      <th>weekday_is_tuesday</th>\n      <th>weekday_is_wednesday</th>\n      <th>weekday_is_thursday</th>\n      <th>weekday_is_friday</th>\n      <th>weekday_is_saturday</th>\n      <th>weekday_is_sunday</th>\n      <th>is_weekend</th>\n      <th>LDA_00</th>\n      <th>LDA_01</th>\n      <th>LDA_02</th>\n      <th>LDA_03</th>\n      <th>LDA_04</th>\n      <th>global_subjectivity</th>\n      <th>global_sentiment_polarity</th>\n      <th>global_rate_positive_words</th>\n      <th>global_rate_negative_words</th>\n      <th>rate_positive_words</th>\n      <th>rate_negative_words</th>\n      <th>avg_positive_polarity</th>\n      <th>min_positive_polarity</th>\n      <th>max_positive_polarity</th>\n      <th>avg_negative_polarity</th>\n      <th>min_negative_polarity</th>\n      <th>max_negative_polarity</th>\n      <th>title_subjectivity</th>\n      <th>title_sentiment_polarity</th>\n      <th>abs_title_subjectivity</th>\n      <th>abs_title_sentiment_polarity</th>\n      <th>shares</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["#Checking duplicate values\npop_df.distinct().count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[5]: 39644</div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["Since all instances are distinct there are no duplicate values."],"metadata":{}},{"cell_type":"markdown","source":["##### *Removing the spaces from the column names*"],"metadata":{}},{"cell_type":"code","source":["x = pop_df.columns \nfor i in x:\n    pop_df = pop_df.withColumnRenamed(i,i.replace(\" \",\"\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["##### *We are removing the columns $url$ and $timedelta$ as the variance in data is 0*"],"metadata":{}},{"cell_type":"code","source":["colnames = ['timedelta','url']\npop_df = pop_df.drop(*colnames)\npop_df.toPandas().head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_tokens_title</th>\n      <th>n_tokens_content</th>\n      <th>n_unique_tokens</th>\n      <th>n_non_stop_words</th>\n      <th>n_non_stop_unique_tokens</th>\n      <th>num_hrefs</th>\n      <th>num_self_hrefs</th>\n      <th>num_imgs</th>\n      <th>num_videos</th>\n      <th>average_token_length</th>\n      <th>num_keywords</th>\n      <th>data_channel_is_lifestyle</th>\n      <th>data_channel_is_entertainment</th>\n      <th>data_channel_is_bus</th>\n      <th>data_channel_is_socmed</th>\n      <th>data_channel_is_tech</th>\n      <th>data_channel_is_world</th>\n      <th>kw_min_min</th>\n      <th>kw_max_min</th>\n      <th>kw_avg_min</th>\n      <th>kw_min_max</th>\n      <th>kw_max_max</th>\n      <th>kw_avg_max</th>\n      <th>kw_min_avg</th>\n      <th>kw_max_avg</th>\n      <th>kw_avg_avg</th>\n      <th>self_reference_min_shares</th>\n      <th>self_reference_max_shares</th>\n      <th>self_reference_avg_sharess</th>\n      <th>weekday_is_monday</th>\n      <th>weekday_is_tuesday</th>\n      <th>weekday_is_wednesday</th>\n      <th>weekday_is_thursday</th>\n      <th>weekday_is_friday</th>\n      <th>weekday_is_saturday</th>\n      <th>weekday_is_sunday</th>\n      <th>is_weekend</th>\n      <th>LDA_00</th>\n      <th>LDA_01</th>\n      <th>LDA_02</th>\n      <th>LDA_03</th>\n      <th>LDA_04</th>\n      <th>global_subjectivity</th>\n      <th>global_sentiment_polarity</th>\n      <th>global_rate_positive_words</th>\n      <th>global_rate_negative_words</th>\n      <th>rate_positive_words</th>\n      <th>rate_negative_words</th>\n      <th>avg_positive_polarity</th>\n      <th>min_positive_polarity</th>\n      <th>max_positive_polarity</th>\n      <th>avg_negative_polarity</th>\n      <th>min_negative_polarity</th>\n      <th>max_negative_polarity</th>\n      <th>title_subjectivity</th>\n      <th>title_sentiment_polarity</th>\n      <th>abs_title_subjectivity</th>\n      <th>abs_title_sentiment_polarity</th>\n      <th>shares</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12.0</td>\n      <td>219.0</td>\n      <td>0.663594</td>\n      <td>1.0</td>\n      <td>0.815385</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.680365</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>496.0</td>\n      <td>496.0</td>\n      <td>496.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.500331</td>\n      <td>0.378279</td>\n      <td>0.040005</td>\n      <td>0.041263</td>\n      <td>0.040123</td>\n      <td>0.521617</td>\n      <td>0.092562</td>\n      <td>0.045662</td>\n      <td>0.013699</td>\n      <td>0.769231</td>\n      <td>0.230769</td>\n      <td>0.378636</td>\n      <td>0.100000</td>\n      <td>0.7</td>\n      <td>-0.350000</td>\n      <td>-0.600</td>\n      <td>-0.200000</td>\n      <td>0.500000</td>\n      <td>-0.187500</td>\n      <td>0.000000</td>\n      <td>0.187500</td>\n      <td>593.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9.0</td>\n      <td>255.0</td>\n      <td>0.604743</td>\n      <td>1.0</td>\n      <td>0.791946</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.913725</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.799756</td>\n      <td>0.050047</td>\n      <td>0.050096</td>\n      <td>0.050101</td>\n      <td>0.050001</td>\n      <td>0.341246</td>\n      <td>0.148948</td>\n      <td>0.043137</td>\n      <td>0.015686</td>\n      <td>0.733333</td>\n      <td>0.266667</td>\n      <td>0.286915</td>\n      <td>0.033333</td>\n      <td>0.7</td>\n      <td>-0.118750</td>\n      <td>-0.125</td>\n      <td>-0.100000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>711.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9.0</td>\n      <td>211.0</td>\n      <td>0.575130</td>\n      <td>1.0</td>\n      <td>0.663866</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.393365</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>918.0</td>\n      <td>918.0</td>\n      <td>918.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.217792</td>\n      <td>0.033334</td>\n      <td>0.033351</td>\n      <td>0.033334</td>\n      <td>0.682188</td>\n      <td>0.702222</td>\n      <td>0.323333</td>\n      <td>0.056872</td>\n      <td>0.009479</td>\n      <td>0.857143</td>\n      <td>0.142857</td>\n      <td>0.495833</td>\n      <td>0.100000</td>\n      <td>1.0</td>\n      <td>-0.466667</td>\n      <td>-0.800</td>\n      <td>-0.133333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1500.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.0</td>\n      <td>531.0</td>\n      <td>0.503788</td>\n      <td>1.0</td>\n      <td>0.665635</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.404896</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.028573</td>\n      <td>0.419300</td>\n      <td>0.494651</td>\n      <td>0.028905</td>\n      <td>0.028572</td>\n      <td>0.429850</td>\n      <td>0.100705</td>\n      <td>0.041431</td>\n      <td>0.020716</td>\n      <td>0.666667</td>\n      <td>0.333333</td>\n      <td>0.385965</td>\n      <td>0.136364</td>\n      <td>0.8</td>\n      <td>-0.369697</td>\n      <td>-0.600</td>\n      <td>-0.166667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1200.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13.0</td>\n      <td>1072.0</td>\n      <td>0.415646</td>\n      <td>1.0</td>\n      <td>0.540890</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>20.0</td>\n      <td>0.0</td>\n      <td>4.682836</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>545.0</td>\n      <td>16000.0</td>\n      <td>3151.157895</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.028633</td>\n      <td>0.028794</td>\n      <td>0.028575</td>\n      <td>0.028572</td>\n      <td>0.885427</td>\n      <td>0.513502</td>\n      <td>0.281003</td>\n      <td>0.074627</td>\n      <td>0.012127</td>\n      <td>0.860215</td>\n      <td>0.139785</td>\n      <td>0.411127</td>\n      <td>0.033333</td>\n      <td>1.0</td>\n      <td>-0.220192</td>\n      <td>-0.500</td>\n      <td>-0.050000</td>\n      <td>0.454545</td>\n      <td>0.136364</td>\n      <td>0.045455</td>\n      <td>0.136364</td>\n      <td>505.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":17},{"cell_type":"markdown","source":["##### *Making a new column $target_shares$ to make the $shares$ into two classes. The two classes are seperated by a threshold value of 1400*"],"metadata":{}},{"cell_type":"code","source":["pop_df_final = pop_df.withColumn(\"target_shares\", lit(0))\ntarget_df = pop_df_final.withColumn(\"target_shares\", \\\n              when(pop_df_final[\"shares\"] < 1400,0).otherwise(1))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["##### *Checking and removing outliers if any*"],"metadata":{}},{"cell_type":"code","source":["viz = target_df.toPandas()\ntil = viz.columns[:-2]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"code","source":["plt.figure(figsize=(15,50))\nfor i in range(len(til)):\n    plt.subplot(10,6,i+1)\n    plt.boxplot(viz[til[i]])\n    plt.title(til[i])\ndisplay()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["bounds = {\n    c: dict(\n        zip([\"q1\", \"q3\"], target_df.approxQuantile(c, [0.25, 0.75], 0))\n    )\n    for c in target_df.columns\n}"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":23},{"cell_type":"code","source":["for c in bounds:\n    iqr = bounds[c]['q3'] - bounds[c]['q1']\n    bounds[c]['lower'] = bounds[c]['q1'] - (iqr * 1.5)\n    bounds[c]['upper'] = bounds[c]['q3'] + (iqr * 1.5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"code","source":["bounds_df = pd.DataFrame(bounds)\nbounds_df"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_tokens_title</th>\n      <th>n_tokens_content</th>\n      <th>n_unique_tokens</th>\n      <th>n_non_stop_words</th>\n      <th>n_non_stop_unique_tokens</th>\n      <th>num_hrefs</th>\n      <th>num_self_hrefs</th>\n      <th>num_imgs</th>\n      <th>num_videos</th>\n      <th>average_token_length</th>\n      <th>num_keywords</th>\n      <th>data_channel_is_lifestyle</th>\n      <th>data_channel_is_entertainment</th>\n      <th>data_channel_is_bus</th>\n      <th>data_channel_is_socmed</th>\n      <th>data_channel_is_tech</th>\n      <th>data_channel_is_world</th>\n      <th>kw_min_min</th>\n      <th>kw_max_min</th>\n      <th>kw_avg_min</th>\n      <th>kw_min_max</th>\n      <th>kw_max_max</th>\n      <th>kw_avg_max</th>\n      <th>kw_min_avg</th>\n      <th>kw_max_avg</th>\n      <th>kw_avg_avg</th>\n      <th>self_reference_min_shares</th>\n      <th>self_reference_max_shares</th>\n      <th>self_reference_avg_sharess</th>\n      <th>weekday_is_monday</th>\n      <th>weekday_is_tuesday</th>\n      <th>weekday_is_wednesday</th>\n      <th>weekday_is_thursday</th>\n      <th>weekday_is_friday</th>\n      <th>weekday_is_saturday</th>\n      <th>weekday_is_sunday</th>\n      <th>is_weekend</th>\n      <th>LDA_00</th>\n      <th>LDA_01</th>\n      <th>LDA_02</th>\n      <th>LDA_03</th>\n      <th>LDA_04</th>\n      <th>global_subjectivity</th>\n      <th>global_sentiment_polarity</th>\n      <th>global_rate_positive_words</th>\n      <th>global_rate_negative_words</th>\n      <th>rate_positive_words</th>\n      <th>rate_negative_words</th>\n      <th>avg_positive_polarity</th>\n      <th>min_positive_polarity</th>\n      <th>max_positive_polarity</th>\n      <th>avg_negative_polarity</th>\n      <th>min_negative_polarity</th>\n      <th>max_negative_polarity</th>\n      <th>title_subjectivity</th>\n      <th>title_sentiment_polarity</th>\n      <th>abs_title_subjectivity</th>\n      <th>abs_title_sentiment_polarity</th>\n      <th>shares</th>\n      <th>target_shares</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>lower</th>\n      <td>4.5</td>\n      <td>-459.0</td>\n      <td>0.264107</td>\n      <td>1.0</td>\n      <td>0.432355</td>\n      <td>-11.0</td>\n      <td>-3.5</td>\n      <td>-3.5</td>\n      <td>-1.5</td>\n      <td>3.913742</td>\n      <td>1.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-8.5</td>\n      <td>-387.5</td>\n      <td>-181.125</td>\n      <td>-11850.0</td>\n      <td>843300.0</td>\n      <td>-64376.25</td>\n      <td>-3085.070000</td>\n      <td>-124.671220</td>\n      <td>555.861416</td>\n      <td>-2302.5</td>\n      <td>-9250.0</td>\n      <td>-5347.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.298796</td>\n      <td>-0.163706</td>\n      <td>-0.429890</td>\n      <td>-0.492182</td>\n      <td>-0.528541</td>\n      <td>0.227910</td>\n      <td>-0.122360</td>\n      <td>-0.004458</td>\n      <td>-0.008570</td>\n      <td>0.3</td>\n      <td>-0.113960</td>\n      <td>0.148431</td>\n      <td>-0.025</td>\n      <td>-1.110223e-16</td>\n      <td>-0.540606</td>\n      <td>-1.3</td>\n      <td>-0.2375</td>\n      <td>-0.75</td>\n      <td>-0.225</td>\n      <td>-0.333333</td>\n      <td>-0.375</td>\n      <td>-1835.0</td>\n      <td>-1.5</td>\n    </tr>\n    <tr>\n      <th>q1</th>\n      <td>9.0</td>\n      <td>246.0</td>\n      <td>0.470860</td>\n      <td>1.0</td>\n      <td>0.625720</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>4.478400</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>445.0</td>\n      <td>141.750</td>\n      <td>0.0</td>\n      <td>843300.0</td>\n      <td>172837.50</td>\n      <td>0.000000</td>\n      <td>3562.101631</td>\n      <td>2382.432871</td>\n      <td>639.0</td>\n      <td>1100.0</td>\n      <td>981.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.025050</td>\n      <td>0.025012</td>\n      <td>0.028571</td>\n      <td>0.028571</td>\n      <td>0.028574</td>\n      <td>0.396164</td>\n      <td>0.057754</td>\n      <td>0.028384</td>\n      <td>0.009615</td>\n      <td>0.6</td>\n      <td>0.185185</td>\n      <td>0.306229</td>\n      <td>0.050</td>\n      <td>6.000000e-01</td>\n      <td>-0.328385</td>\n      <td>-0.7</td>\n      <td>-0.1250</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.166667</td>\n      <td>0.000</td>\n      <td>946.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>q3</th>\n      <td>12.0</td>\n      <td>716.0</td>\n      <td>0.608696</td>\n      <td>1.0</td>\n      <td>0.754630</td>\n      <td>14.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>4.854839</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1000.0</td>\n      <td>357.000</td>\n      <td>7900.0</td>\n      <td>843300.0</td>\n      <td>330980.00</td>\n      <td>2056.713333</td>\n      <td>6019.950198</td>\n      <td>3600.147174</td>\n      <td>2600.0</td>\n      <td>8000.0</td>\n      <td>5200.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.240948</td>\n      <td>0.150825</td>\n      <td>0.334212</td>\n      <td>0.375740</td>\n      <td>0.399984</td>\n      <td>0.508333</td>\n      <td>0.177829</td>\n      <td>0.050279</td>\n      <td>0.021739</td>\n      <td>0.8</td>\n      <td>0.384615</td>\n      <td>0.411428</td>\n      <td>0.100</td>\n      <td>1.000000e+00</td>\n      <td>-0.186905</td>\n      <td>-0.3</td>\n      <td>-0.0500</td>\n      <td>0.50</td>\n      <td>0.150</td>\n      <td>0.500000</td>\n      <td>0.250</td>\n      <td>2800.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>upper</th>\n      <td>16.5</td>\n      <td>1421.0</td>\n      <td>0.815449</td>\n      <td>1.0</td>\n      <td>0.947994</td>\n      <td>29.0</td>\n      <td>8.5</td>\n      <td>8.5</td>\n      <td>2.5</td>\n      <td>5.419497</td>\n      <td>13.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>11.5</td>\n      <td>1832.5</td>\n      <td>679.875</td>\n      <td>19750.0</td>\n      <td>843300.0</td>\n      <td>568193.75</td>\n      <td>5141.783333</td>\n      <td>9706.723049</td>\n      <td>5426.718630</td>\n      <td>5541.5</td>\n      <td>18350.0</td>\n      <td>11528.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.564795</td>\n      <td>0.339543</td>\n      <td>0.792674</td>\n      <td>0.896493</td>\n      <td>0.957099</td>\n      <td>0.676587</td>\n      <td>0.357943</td>\n      <td>0.083122</td>\n      <td>0.039925</td>\n      <td>1.1</td>\n      <td>0.683761</td>\n      <td>0.569226</td>\n      <td>0.175</td>\n      <td>1.600000e+00</td>\n      <td>0.025316</td>\n      <td>0.3</td>\n      <td>0.0625</td>\n      <td>1.25</td>\n      <td>0.375</td>\n      <td>1.000000</td>\n      <td>0.625</td>\n      <td>5581.0</td>\n      <td>2.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":25},{"cell_type":"markdown","source":["##### *Winsorizing the outliers*"],"metadata":{}},{"cell_type":"code","source":["new_df=target_df\nnew_df=new_df.withColumn('n_tokens_title',when(new_df['n_tokens_title']>16.5,16.5).otherwise(new_df['n_tokens_title']))\nnew_df=new_df.withColumn('n_tokens_content',when(new_df['n_tokens_content']>1421,1421).otherwise(new_df['n_tokens_content']))\nnew_df=new_df.withColumn('n_unique_tokens',when(new_df['n_unique_tokens']>0.815449,0.815449).otherwise(new_df['n_unique_tokens']))\nnew_df=new_df.withColumn('n_non_stop_words',when(new_df['n_non_stop_words']>1.0,1.0).otherwise(new_df['n_non_stop_words']))\nnew_df=new_df.withColumn('n_non_stop_unique_tokens',when(new_df['n_non_stop_unique_tokens']>0.947994,0.947994).otherwise(new_df['n_non_stop_unique_tokens']))\nnew_df=new_df.withColumn('num_hrefs',when(new_df['num_hrefs']>29,29).otherwise(new_df['num_hrefs']))\nnew_df=new_df.withColumn('num_self_hrefs',when(new_df['num_self_hrefs']>8.5,8.5).otherwise(new_df['num_self_hrefs']))\nnew_df=new_df.withColumn('num_imgs',when(new_df['num_imgs']>8.5,8.5).otherwise(new_df['num_imgs']))\nnew_df=new_df.withColumn('num_videos',when(new_df['num_videos']>2.5,2.5).otherwise(new_df['num_videos']))\nnew_df=new_df.withColumn('average_token_length',when(new_df['average_token_length']>5.419497,5.419497).otherwise(new_df['average_token_length']))\nnew_df=new_df.withColumn('kw_min_min',when(new_df['kw_min_min']>11.5,11.5).otherwise(new_df['kw_min_min']))\nnew_df=new_df.withColumn('kw_max_min',when(new_df['kw_max_min']>1832.5,1832.5).otherwise(new_df['kw_max_min']))\nnew_df=new_df.withColumn('kw_avg_min',when(new_df['kw_avg_min']>679.875,679.875).otherwise(new_df['kw_avg_min']))\nnew_df=new_df.withColumn('kw_min_max',when(new_df['kw_min_max']>19750.0,19750.0).otherwise(new_df['kw_min_max']))\nnew_df=new_df.withColumn('kw_max_max',when(new_df['kw_max_max']>843300.0,843300.0).otherwise(new_df['kw_max_min']))\nnew_df=new_df.withColumn('kw_avg_max',when(new_df['kw_avg_max']>568193.75,568193.75).otherwise(new_df['kw_avg_max']))\nnew_df=new_df.withColumn('kw_min_avg',when(new_df['kw_min_avg']>5141.783333325,5141.783333325).otherwise(new_df['kw_min_avg']))\nnew_df=new_df.withColumn('kw_max_avg',when(new_df['kw_max_avg']>9706.723048789998,9706.723048789998).otherwise(new_df['kw_max_avg']))\nnew_df=new_df.withColumn('kw_avg_avg',when(new_df['kw_avg_avg']>5426.718629630001,5426.718629630001).otherwise(new_df['kw_avg_avg']))\nnew_df=new_df.withColumn('self_reference_min_shares',when(new_df['self_reference_min_shares']>5541.5,5541.5).otherwise(new_df['self_reference_min_shares']))\nnew_df=new_df.withColumn('self_reference_max_shares',when(new_df['self_reference_max_shares']>18350.0,18350.0).otherwise(new_df['self_reference_max_shares']))\nnew_df=new_df.withColumn('self_reference_avg_sharess',when(new_df['self_reference_avg_sharess']>11528.5,11528.5).otherwise(new_df['self_reference_avg_sharess']))\nnew_df=new_df.withColumn('LDA_00',when(new_df['LDA_00']>0.56479460105095,0.56479460105095).otherwise(new_df['LDA_00']))\nnew_df=new_df.withColumn('LDA_01',when(new_df['LDA_01']>0.3395427123779,0.3395427123779).otherwise(new_df['LDA_01']))\nnew_df=new_df.withColumn('LDA_02',when(new_df['LDA_02']>0.7926739292770502,0.7926739292770502).otherwise(new_df['LDA_02']))\nnew_df=new_df.withColumn('LDA_03',when(new_df['LDA_03']>0.89649332233195,0.89649332233195).otherwise(new_df['LDA_03']))\nnew_df=new_df.withColumn('LDA_04',when(new_df['LDA_04']>0.9570986642896501,0.9570986642896501).otherwise(new_df['LDA_04']))\nnew_df=new_df.withColumn('title_sentiment_polarity',when(new_df['title_sentiment_polarity']>0.375,0.375).otherwise(new_df['title_sentiment_polarity']))\nnew_df=new_df.withColumn('global_sentiment_polarity',when(new_df['global_sentiment_polarity']>0.3579429499083,0.3579429499083).otherwise(new_df['global_sentiment_polarity']))\nnew_df=new_df.withColumn('global_rate_positive_words',when(new_df['global_rate_positive_words']>0.08312190480824999,0.08312190480824999).otherwise(new_df['global_rate_positive_words']))\nnew_df=new_df.withColumn('global_rate_negative_words',when(new_df['global_rate_negative_words']>0.039924749163930004,0.039924749163930004).otherwise(new_df['global_rate_negative_words']))\nnew_df=new_df.withColumn('global_subjectivity',when(new_df['global_subjectivity']>0.6765873015865,0.6765873015865).otherwise(new_df['global_subjectivity']))\nnew_df=new_df.withColumn('rate_negative_words',when(new_df['rate_negative_words']>0.68376068376,0.68376068376).otherwise(new_df['rate_negative_words']))\nnew_df=new_df.withColumn('avg_negative_polarity',when(new_df['avg_negative_polarity']>0.02531622023800001,0.02531622023800001).otherwise(new_df['avg_negative_polarity']))\nnew_df=new_df.withColumn('min_negative_polarity',when(new_df['min_negative_polarity']>0.3,0.3).otherwise(new_df['min_negative_polarity']))\nnew_df=new_df.withColumn('abs_title_sentiment_polarity',when(new_df['abs_title_sentiment_polarity']>0.625,0.625).otherwise(new_df['abs_title_sentiment_polarity']))\nnew_df=new_df.withColumn('avg_positive_polarity',when(new_df['avg_positive_polarity']>0.5692255345665,0.5692255345665).otherwise(new_df['avg_positive_polarity']))\nnew_df=new_df.withColumn('min_positive_polarity',when(new_df['min_positive_polarity']>0.17500000000000002,0.17500000000000002).otherwise(new_df['min_positive_polarity']))\nnew_df=new_df.withColumn('n_tokens_title',when(new_df['n_tokens_title']<4.5,4.5).otherwise(new_df['n_tokens_title']))\nnew_df=new_df.withColumn('n_unique_tokens',when(new_df['n_unique_tokens']<0.2641073126304999,0.2641073126304999).otherwise(new_df['n_unique_tokens']))\nnew_df=new_df.withColumn('n_non_stop_unique_tokens',when(new_df['n_non_stop_unique_tokens']<0.43235498197850003,0.43235498197850003).otherwise(new_df['n_non_stop_unique_tokens']))\nnew_df=new_df.withColumn('average_token_length',when(new_df['average_token_length']<3.913741935479999,3.913741935479999).otherwise(new_df['average_token_length']))\nnew_df=new_df.withColumn('kw_avg_avg',when(new_df['kw_avg_avg']<555.86141587,555.86141587).otherwise(new_df['kw_avg_avg']))\nnew_df=new_df.withColumn('global_sentiment_polarity',when(new_df['global_sentiment_polarity']<-0.12236008039650,-0.12236008039650).otherwise(new_df['global_sentiment_polarity']))\nnew_df=new_df.withColumn('global_subjectivity',when(new_df['global_subjectivity']<0.2279100529105,0.2279100529105).otherwise(new_df['global_subjectivity']))\nnew_df=new_df.withColumn('rate_positive_words',when(new_df['rate_positive_words']<0.2999999999999999,0.2999999999999999).otherwise(new_df['rate_positive_words']))\nnew_df=new_df.withColumn('avg_positive_polarity',when(new_df['avg_positive_polarity']<0.148431009226499965,0.14843100922649996).otherwise(new_df['avg_positive_polarity']))\nnew_df=new_df.withColumn('avg_negative_polarity',when(new_df['avg_negative_polarity']<-0.54060639881,-0.54060639881).otherwise(new_df['avg_negative_polarity']))\nnew_df=new_df.withColumn('max_negative_polarity',when(new_df['max_negative_polarity']<-0.2375,-0.2375).otherwise(new_df['max_negative_polarity']))\nnew_df=new_df.withColumn('title_sentiment_polarity',when(new_df['title_sentiment_polarity']<-0.22499999999999998,-0.22499999999999998).otherwise(new_df['title_sentiment_polarity']))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"markdown","source":["### Exploratory Data Analysis and Visualization"],"metadata":{}},{"cell_type":"markdown","source":["##### Converting the weekday dummies into categorical variable"],"metadata":{}},{"cell_type":"code","source":["df = new_df.toPandas().copy()\nday = df[['weekday_is_monday','weekday_is_tuesday','weekday_is_wednesday','weekday_is_thursday', \n          'weekday_is_friday','weekday_is_saturday' ,'weekday_is_sunday' ]]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":30},{"cell_type":"code","source":["temp_arr=[]\nfor r in list(range(day.shape[0])):\n    for c in list(range(day.shape[1])):\n        if ((c==0) and (day.iloc[r,c])==1):\n            temp_arr.append('Monday')\n        elif ((c==1) and (day.iloc[r,c])==1):\n            temp_arr.append('Tuesday')\n        elif ((c==2) and (day.iloc[r,c])==1):\n            temp_arr.append('Wednesday')\n        elif ((c==3) and (day.iloc[r,c])==1):\n            temp_arr.append('Thursday')\n        elif ((c==4) and (day.iloc[r,c])==1):\n            temp_arr.append('Friday')\n        elif ((c==5) and (day.iloc[r,c])==1):\n            temp_arr.append('Saturday') \n        elif ((c==6) and (day.iloc[r,c])==1):\n            temp_arr.append('Sunday')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["##### Converting the data channel dummies into categorical variable"],"metadata":{}},{"cell_type":"code","source":["datachannel=df[['data_channel_is_lifestyle','data_channel_is_entertainment' ,'data_channel_is_bus','data_channel_is_socmed' ,\n                'data_channel_is_tech', 'data_channel_is_world' ]]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":33},{"cell_type":"code","source":["datachannel_arr=[]\nfor r in list(range(datachannel.shape[0])):\n    if (((datachannel.iloc[r,0])==0) and ((datachannel.iloc[r,1])==0) and ((datachannel.iloc[r,2])==0) and ((datachannel.iloc[r,3])==0) and ((datachannel.iloc[r,4])==0) and ((datachannel.iloc[r,5])==0)):\n        datachannel_arr.append('Others')\n    for c in list(range(datachannel.shape[1])):\n        if ((c==0) and (datachannel.iloc[r,c])==1):\n            datachannel_arr.append('Lifestyle')\n        elif ((c==1) and (datachannel.iloc[r,c])==1):\n            datachannel_arr.append('Entertainment')\n        elif ((c==2) and (datachannel.iloc[r,c])==1):\n            datachannel_arr.append('Business')\n        elif ((c==3) and (datachannel.iloc[r,c])==1):\n            datachannel_arr.append('Social Media')\n        elif ((c==4) and (datachannel.iloc[r,c])==1):\n            datachannel_arr.append('Tech')\n        elif ((c==5) and (datachannel.iloc[r,c])==1):\n            datachannel_arr.append('World')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":34},{"cell_type":"code","source":["df.insert(loc=11, column='weekdays', value=temp_arr)\ndf.insert(loc=12, column='data_channel', value=datachannel_arr)\n\n# Now drop the old data\ndf.drop(labels=['data_channel_is_lifestyle','data_channel_is_entertainment' ,'data_channel_is_bus',\n                        'data_channel_is_socmed' ,'data_channel_is_tech','data_channel_is_world', \n                 'weekday_is_monday','weekday_is_tuesday','weekday_is_wednesday', \n                      'weekday_is_thursday', 'weekday_is_friday','weekday_is_saturday' ,'weekday_is_sunday'], \n        axis = 1, inplace=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"markdown","source":["##### Target Variable count plot"],"metadata":{}},{"cell_type":"code","source":["plt.figure(figsize=(5,7))\nsb.countplot(df['target_shares'])\nplt.title('Distribution of target shares')\ndisplay()"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":["##### Features"],"metadata":{}},{"cell_type":"code","source":["plt.figure(figsize=(30,15))\n\nplt.subplot(1,2,1)\na=sb.countplot(df['weekdays'])#hue=df['target_shares'])\nfor p in a.patches:\n        a.annotate(format(p.get_height()), (p.get_x() + p.get_width() / 2., \n        p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points', fontsize = 17)\nplt.title('Weekdays',fontsize=15)\n        \nplt.subplot(1,2,2)\nb=sb.countplot(df['data_channel'])#hue=df['target_shares'])\nfor p in b.patches:\n        b.annotate(format(p.get_height()), (p.get_x() + p.get_width() / 2., \n        p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points', fontsize = 17)\nplt.title('Data Channel',fontsize=15)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["*As you can see, the weekdays have the highest number of shares. Wednesday, Tuesday, Thursday and Monday have the highest number of shares, with Friday having a significant drop.*\n\n*We can also see which category or topic does the best. Here is a bar chart for the seven categories Tech, Entertainment, World, Business, Social Media, Lifestyle and Others.*\n\n*The best performing category is World, followed by Tech, Entertainment, Business. The least popular categories are Social Media and Lifestyle.*"],"metadata":{}},{"cell_type":"code","source":["plt.figure(figsize=(20,5))\nplt.subplot(1,2,1)\nsb.boxplot(y=df['num_hrefs'],x=df['target_shares'])\nplt.title('Num of links vs target shares')\n\nplt.subplot(1,2,2)\nsb.boxplot(y=df['num_self_hrefs'],x=df['target_shares'])\nplt.title('Num of links to other Mashable articles vs target shares')\ndisplay()"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["plt.figure(figsize=(25,10))\nplt.subplot(1,3,1)\nsb.boxplot(y=df['self_reference_min_shares'],x=df['target_shares'])\nplt.title('Minimum shares of Self referenced links')\n\nplt.subplot(1,3,2)\nsb.boxplot(y=df['self_reference_avg_sharess'],x=df['target_shares'])\nplt.title('Average shares of Self referenced links')\n\nplt.subplot(1,3,3)\nsb.boxplot(y=df['self_reference_max_shares'],x=df['target_shares'])\nplt.title('Maximum shares of Self referenced links')\n\ndisplay()"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":["*When there are links embedded in the news article which point them to stories by other sources or referring to the news on their own website, seems to increase the popularity. If we look at both the references, the popularity increases when they refer the links from mashable compared to other online sources.*"],"metadata":{}},{"cell_type":"code","source":["plt.figure(figsize=(15,7))\nplt.subplot(1,2,1)\nsb.boxplot(y=df['global_sentiment_polarity'],x=df['target_shares'])\nplt.title('global sentiment polarity vs target shares')\n\nplt.subplot(1,2,2)\nsb.boxplot(y=df['global_subjectivity'],x=df['target_shares'])\nplt.title('global subjectivity vs target shares')\n\ndisplay()"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":["**Polarity** *in sentiment analysis refers to identifying sentiment orientation (positive, neutral, and negative) in written or spoken language.*\n\n**Subjectivity** *refers to the quality of being based on or influenced by personal feelings, tastes, or opinions.*\n\n\n*The articles with more subjectivity and polarity tend to be more popular among the online news.*"],"metadata":{}},{"cell_type":"code","source":["plt.figure(figsize=(14,7))\nsb.countplot(df['data_channel'],hue = df['target_shares'])\nplt.title('Data Channel wrt target shares')\ndisplay()"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":["**No. of words in title and content**"],"metadata":{}},{"cell_type":"code","source":["plt.figure(figsize=(30,10))\nplt.subplot(1,3,1)\nsb.countplot(df['n_tokens_title'],hue=df['target_shares'])\nplt.title('Num of tokens in title wrt target shares')\n\nplt.subplot(1,3,2)\nsb.boxplot(y=df['n_tokens_content'],x=df['target_shares'])\nplt.title('Num of tokens in content wrt target shares')\n\nplt.subplot(1,3,3)\nsb.boxplot(y=df['n_unique_tokens'],x=df['target_shares'])\nplt.title('Num of unique tokens wrt target shares')\ndisplay()"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":["**Num of keywords**"],"metadata":{}},{"cell_type":"code","source":["plt.figure(figsize=(14,7))\nsb.countplot(df['num_keywords'],hue=df['target_shares'])\nplt.title('Num of keywords wrt target shares')\ndisplay()"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["plt.figure(figsize=(20,20))\nplt.subplot(3,1,1)\nsb.boxplot(x=df['data_channel'],y=df['min_positive_polarity'])\nplt.title(\"minimum positive polarity vs channel\")\n\nplt.subplot(3,1,2)\nsb.boxplot(x=df['data_channel'],y=df['avg_positive_polarity'])\nplt.title(\"average positive polarity vs channel\")\n\nplt.subplot(3,1,3)\nsb.boxplot(x=df['data_channel'],y=df['max_positive_polarity'])\nplt.title(\"maximum positive polarity vs channel\")\ndisplay()"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":["### Logistic Regression"],"metadata":{}},{"cell_type":"markdown","source":["##### Base Model"],"metadata":{}},{"cell_type":"code","source":["training_df, testing_df = new_df.randomSplit([0.7, 0.3],seed=42)\nv = VectorAssembler().setInputCols(training_df.columns[:-2]).setOutputCol('cfeatures')\nbc = BinaryClassificationEvaluator(labelCol='target_shares')\nscale = feature.StandardScaler(withMean=True, withStd=False, inputCol='cfeatures', outputCol='sfeatures')\nlr = LogisticRegression(featuresCol = 'sfeatures',labelCol = 'target_shares',regParam = 0.1)\nlr_pipeline = Pipeline(stages=[v, scale, lr])\nlr_fitted = lr_pipeline.fit(training_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":54},{"cell_type":"code","source":["print('The AUC Score: ',bc.evaluate(lr_fitted.transform(testing_df)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The AUC Score:  0.7094810208352733\n</div>"]}}],"execution_count":55},{"cell_type":"code","source":["x = lr_fitted.transform(testing_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":56},{"cell_type":"markdown","source":["##### Metrics"],"metadata":{}},{"cell_type":"code","source":["evaluator = MulticlassClassificationEvaluator(labelCol='target_shares', predictionCol='prediction', metricName='accuracy')\naccuracy = evaluator.evaluate(x)\nprint(\"Accuracy = %g\" % accuracy)\nevaluatorf1 = MulticlassClassificationEvaluator(labelCol='target_shares', predictionCol='prediction', metricName='f1')\nf1 = evaluatorf1.evaluate(x)\nprint(\"f1 = %g\" % f1)\nevaluatorwp = MulticlassClassificationEvaluator(labelCol='target_shares', predictionCol='prediction',\n                                                metricName=\"weightedPrecision\")\nwp = evaluatorwp.evaluate(x)\nprint(\"Precision = %g\" % wp)\nevaluatorwr = MulticlassClassificationEvaluator(labelCol='target_shares', predictionCol='prediction', \n                                                metricName=\"weightedRecall\")\nwr = evaluatorwr.evaluate(x)\nprint(\"Recall = %g\" % wr)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy = 0.655088\nf1 = 0.654211\nPrecision = 0.654162\nRecall = 0.655088\n</div>"]}}],"execution_count":58},{"cell_type":"markdown","source":["##### Grid Search"],"metadata":{}},{"cell_type":"code","source":["#lrparamGrid = ParamGridBuilder().addGrid(lr.regParam, [0.1,0.2]).addGrid(lr.elasticNetParam, [0.01,0.02]).build()\n#lrcv = CrossValidator(estimator=lr_pipeline,\n#                          estimatorParamMaps=lrparamGrid,\n#                          evaluator=bc,\n#                          numFolds=3)\n#lrcvModel = lrcv.fit(training_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":60},{"cell_type":"code","source":["#lrpipe = lrcvModel.bestModel.stages[1]\n#lrbest = lrpipe.extractParamMap()\n\n#print(lrbest[lrpipe.getParam('regParam')])\n#print(lrbest[lrpipe.getParam('elasticNetParam')])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":61},{"cell_type":"markdown","source":["##### Best Model"],"metadata":{}},{"cell_type":"code","source":["lr_best = LogisticRegression(featuresCol = 'sfeatures',labelCol = 'target_shares',regParam = 0.1,elasticNetParam = 0.01)\nlr_pipeline_best = Pipeline(stages=[v,scale, lr_best])\nlr_fitted_best = lr_pipeline_best.fit(training_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":63},{"cell_type":"code","source":["print('The AUC Score: ',bc.evaluate(lr_fitted_best.transform(testing_df)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The AUC Score:  0.7094249018082257\n</div>"]}}],"execution_count":64},{"cell_type":"code","source":["x_best = lr_fitted_best.transform(testing_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":65},{"cell_type":"markdown","source":["##### Metrics"],"metadata":{}},{"cell_type":"code","source":["accuracy = evaluator.evaluate(x_best)\nprint(\"Accuracy = %g\" % accuracy)\nf1 = evaluatorf1.evaluate(x_best)\nprint(\"f1 = %g\" % f1)\nwp = evaluatorwp.evaluate(x_best)\nprint(\"Precision = %g\" % wp)\nwr = evaluatorwr.evaluate(x_best)\nprint(\"Recall = %g\" % wr)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy = 0.654665\nf1 = 0.653731\nPrecision = 0.65371\nRecall = 0.654665\n</div>"]}}],"execution_count":67},{"cell_type":"markdown","source":["##### ROC Curve for Logistic Regression"],"metadata":{}},{"cell_type":"code","source":["fpr = lr_fitted_best.stages[2].summary.roc.select('FPR').collect()\ntpr = lr_fitted_best.stages[2].summary.roc.select('TPR').collect()\n\nplt.figure(figsize=(10, 6))\nplt.scatter(fpr, tpr, linewidth=1, label='Best',color='green')\nplt.plot([0, 1], [0, 1],linestyle='--', label='Random',color='blue')                                 \nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16) \nplt.title('ROC for the Logistic Regression')\nplt.legend()\nplt.grid(True)  \ndisplay()"],"metadata":{},"outputs":[],"execution_count":69},{"cell_type":"markdown","source":["### Random Forest"],"metadata":{}},{"cell_type":"markdown","source":["##### Base Model"],"metadata":{}},{"cell_type":"code","source":["v = VectorAssembler().setInputCols(training_df.columns[:-2]).setOutputCol('cfeatures')\nrf = RandomForestClassifier(featuresCol='cfeatures',labelCol='target_shares')\nrf_pipe = Pipeline(stages=[v, rf])\nrf_pipeline = rf_pipe.fit(training_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[40]: 0.7074002060456196</div>"]}}],"execution_count":72},{"cell_type":"code","source":["print('The AUC score: ',bc.evaluate(rf_pipeline.transform(testing_df)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The AUC score:  0.707400206045619\n</div>"]}}],"execution_count":73},{"cell_type":"code","source":["lr_df = rf_pipeline.transform(testing_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":74},{"cell_type":"markdown","source":["##### Metrics"],"metadata":{}},{"cell_type":"code","source":["accuracy = evaluator.evaluate(lr_df)\nprint(\"Accuracy = %g\" % accuracy)\nf1 = evaluatorf1.evaluate(lr_df)\nprint(\"f1 = %g\" % f1)\nwp = evaluatorwp.evaluate(lr_df)\nprint(\"Precision = %g\" % wp)\nwr = evaluatorwr.evaluate(lr_df)\nprint(\"Recall = %g\" % wr)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy = 0.650947\nf1 = 0.647191\nPrecision = 0.650251\nRecall = 0.650947\n</div>"]}}],"execution_count":76},{"cell_type":"markdown","source":["##### Grid Search"],"metadata":{}},{"cell_type":"code","source":["#rfparamGrid = (ParamGridBuilder().addGrid(rf.maxDepth, [3,6,9]).addGrid(rf.numTrees, [100,150]).addGrid(rf.featureSubsetStrategy,['log2','all','auto']).build())\n#rfcv = CrossValidator(estimator = rf_pipe ,estimatorParamMaps = rfparamGrid, evaluator = bc, numFolds = 3)\n#rfcvModel = rfcv.fit(training_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":78},{"cell_type":"code","source":["#bestPipeline = rfcvModel.bestModel.stages[1]\n#bestParams = bestPipeline.extractParamMap()\n\n#var_nam = ['maxDepth','numTrees','impurity','AUC Score']\n#var_val = [bestParams[bestPipeline.getParam('maxDepth')],bestParams[bestPipeline.getParam('numTrees')],\n#            bestParams[bestPipeline.getParam('featureSubsetStrategy')],0.8]\n#var_val"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":79},{"cell_type":"markdown","source":["##### Best Model"],"metadata":{}},{"cell_type":"code","source":["rf_best = RandomForestClassifier(featuresCol='cfeatures',labelCol='target_shares',numTrees=150,maxDepth=9,featureSubsetStrategy='auto')\nrf_pipe_best = Pipeline(stages=[v, rf_best])\nrf_pipeline_best = rf_pipe_best.fit(training_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":81},{"cell_type":"code","source":["print('The AUC Score: ',bc.evaluate(rf_pipeline_best.transform(testing_df)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The AUC Score:  0.7255662339428963\n</div>"]}}],"execution_count":82},{"cell_type":"code","source":["t = rf_pipeline_best.transform(testing_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":83},{"cell_type":"markdown","source":["##### Metrics"],"metadata":{}},{"cell_type":"code","source":["evaluatorac = MulticlassClassificationEvaluator(labelCol='target_shares', predictionCol='prediction', metricName='accuracy')\naccuracy = evaluatorac.evaluate(t)\nprint(\"Accuracy = %g\" % accuracy)\nevaluator_f = MulticlassClassificationEvaluator(labelCol='target_shares', predictionCol='prediction', metricName='f1')\nf = evaluator_f.evaluate(t)\nprint(\"f1 = %g\" % f)\nevaluator_re = MulticlassClassificationEvaluator(labelCol='target_shares', predictionCol='prediction', metricName='weightedRecall')\nre = evaluator_re.evaluate(t)\nprint(\"Recall = %g\" % re)\nevaluator_wp = MulticlassClassificationEvaluator(labelCol='target_shares', predictionCol='prediction', metricName='weightedPrecision')\npr = evaluator_wp.evaluate(t)\nprint(\"Precision = %g\" % pr)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy = 0.665061\nf1 = 0.663181\nRecall = 0.665061\nPrecision = 0.664111\n</div>"]}}],"execution_count":85},{"cell_type":"markdown","source":["##### ROC Curve"],"metadata":{}},{"cell_type":"code","source":["preds = t.select('target_shares','probability').rdd.\\\n        map(lambda row: (float(row['probability'][1]), float(row['target_shares']))).collect()\n\ny_score, y_true = zip(*preds)\nfpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label = 1)\n\nplt.figure(figsize=(10, 6))\nplt.scatter(fpr, tpr, linewidth=1, label='Best',color='green')\nplt.plot([0, 1], [0, 1],linestyle='--', label='Random',color='blue')                                 \nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16) \nplt.title('ROC for the Random Forest')\nplt.legend()\nplt.grid(True)  \ndisplay()"],"metadata":{},"outputs":[],"execution_count":87},{"cell_type":"markdown","source":["##### Feature Importance"],"metadata":{}},{"cell_type":"code","source":["bestModel = rf_pipeline_best.stages[1]\nimportances = bestModel.featureImportances\n\npd.DataFrame(list(zip(new_df.columns[:-2], bestModel.featureImportances.toArray())),\n            columns = ['feature', 'importance']).sort_values('importance',ascending=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25</th>\n      <td>kw_avg_avg</td>\n      <td>0.080578</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>self_reference_min_shares</td>\n      <td>0.066876</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>kw_max_avg</td>\n      <td>0.066696</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>is_weekend</td>\n      <td>0.044761</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>self_reference_avg_sharess</td>\n      <td>0.043160</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>data_channel_is_entertainment</td>\n      <td>0.039621</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>LDA_02</td>\n      <td>0.036206</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>kw_min_avg</td>\n      <td>0.032407</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>data_channel_is_world</td>\n      <td>0.028397</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>self_reference_max_shares</td>\n      <td>0.023281</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>LDA_04</td>\n      <td>0.022420</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>data_channel_is_tech</td>\n      <td>0.021535</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>n_unique_tokens</td>\n      <td>0.020836</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>num_hrefs</td>\n      <td>0.020195</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>LDA_01</td>\n      <td>0.019996</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>kw_avg_min</td>\n      <td>0.019953</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>n_non_stop_unique_tokens</td>\n      <td>0.019161</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>LDA_00</td>\n      <td>0.019052</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>kw_avg_max</td>\n      <td>0.018931</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>data_channel_is_socmed</td>\n      <td>0.018602</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>weekday_is_saturday</td>\n      <td>0.018442</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>global_subjectivity</td>\n      <td>0.015173</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>n_tokens_content</td>\n      <td>0.015150</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>num_imgs</td>\n      <td>0.014810</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>LDA_03</td>\n      <td>0.013633</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>n_non_stop_words</td>\n      <td>0.013442</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>global_sentiment_polarity</td>\n      <td>0.013331</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>kw_max_max</td>\n      <td>0.013103</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>average_token_length</td>\n      <td>0.013027</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>global_rate_positive_words</td>\n      <td>0.012892</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>rate_negative_words</td>\n      <td>0.012498</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>min_positive_polarity</td>\n      <td>0.012127</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>kw_max_min</td>\n      <td>0.012077</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>avg_positive_polarity</td>\n      <td>0.011636</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>rate_positive_words</td>\n      <td>0.010885</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>global_rate_negative_words</td>\n      <td>0.010693</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>avg_negative_polarity</td>\n      <td>0.010594</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>kw_min_min</td>\n      <td>0.010029</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>kw_min_max</td>\n      <td>0.009614</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>n_tokens_title</td>\n      <td>0.009182</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>num_keywords</td>\n      <td>0.009020</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>min_negative_polarity</td>\n      <td>0.007562</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>title_sentiment_polarity</td>\n      <td>0.007421</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>num_self_hrefs</td>\n      <td>0.007278</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>max_negative_polarity</td>\n      <td>0.007273</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>weekday_is_sunday</td>\n      <td>0.007005</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>abs_title_subjectivity</td>\n      <td>0.006360</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>title_subjectivity</td>\n      <td>0.005782</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>max_positive_polarity</td>\n      <td>0.005574</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>abs_title_sentiment_polarity</td>\n      <td>0.005481</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>num_videos</td>\n      <td>0.004655</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>data_channel_is_bus</td>\n      <td>0.004240</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>weekday_is_wednesday</td>\n      <td>0.001400</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>weekday_is_friday</td>\n      <td>0.001289</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>weekday_is_tuesday</td>\n      <td>0.001207</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>weekday_is_monday</td>\n      <td>0.001179</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>data_channel_is_lifestyle</td>\n      <td>0.001159</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>weekday_is_thursday</td>\n      <td>0.001116</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":89},{"cell_type":"code","source":["x_values = list(range(len(importances)))\nplt.figure(figsize=(10,5))\nplt.bar(x_values, importances, orientation = 'vertical')\nplt.xticks(x_values, training_df.columns[:-2], rotation=90)\nplt.ylabel('Importance')\nplt.xlabel('Feature')\nplt.title('Feature Importance')\ndisplay()"],"metadata":{},"outputs":[],"execution_count":90},{"cell_type":"markdown","source":["## Gradient Boosting"],"metadata":{}},{"cell_type":"markdown","source":["##### Base Model"],"metadata":{}},{"cell_type":"code","source":["gbt = GBTClassifier(featuresCol='cfeatures',labelCol='target_shares')\ngbt_pipe = Pipeline(stages=[v, gbt])\ngbt_pipeline = gbt_pipe.fit(training_df)\nbc = BinaryClassificationEvaluator(labelCol='target_shares')\nprediction = gbt_pipeline.transform(testing_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":93},{"cell_type":"code","source":["print('The AUC Score: ',bc.evaluate(prediction))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The AUC Score:  0.7219886675196484\n</div>"]}}],"execution_count":94},{"cell_type":"markdown","source":["##### Metrics"],"metadata":{}},{"cell_type":"code","source":["evaluator = MulticlassClassificationEvaluator(labelCol='target_shares', metricName='accuracy')\naccuracy = evaluator.evaluate(prediction)\nprint(\"Accuracy = %g\" % accuracy)\nevaluator_f = MulticlassClassificationEvaluator(labelCol='target_shares', metricName='f1')\nf1 = evaluator_f.evaluate(prediction)\nprint(\"f1 = %g\" % f1)\nevaluator_re = MulticlassClassificationEvaluator(labelCol='target_shares', metricName='weightedRecall')\nrec = evaluator_re.evaluate(prediction)\nprint(\"Recall = %g\" % rec)\nevaluator_wp = MulticlassClassificationEvaluator(labelCol='target_shares', metricName='weightedPrecision')\npre = evaluator_wp.evaluate(prediction)\nprint(\"Precision = %g\" % pre)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy = 0.664554\nf1 = 0.664036\nRecall = 0.664554\nPrecision = 0.663888\n</div>"]}}],"execution_count":96},{"cell_type":"markdown","source":["##### Grid Search"],"metadata":{}},{"cell_type":"code","source":["#paramGrid = ParamGridBuilder()\\\n#            .addGrid(gbt.maxDepth, [2,5,9])\\\n#            .addGrid(gbt.featureSubsetStrategy, ['all'])\\\n#            .addGrid(gbt.minInstancesPerNode, [1,3])\\\n#            .addGrid(gbt.stepSize, [0.01,0.1,1]).build()\n#crossval = CrossValidator(estimator=gbt_pipe, estimatorParamMaps=paramGrid, evaluator=bc, numFolds=3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":98},{"cell_type":"code","source":["#model = crossval.fit(training_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":99},{"cell_type":"code","source":["#gb_bestpipe = model.bestModel.stages[1]\n#gb_best = gb_bestpipe.extractParamMap()\n\n#print(gb_best[gb_bestpipe.getParam('regParam')])\n#print(gb_best[gb_bestpipe.getParam('elasticNetParam')])\n#print(\"trained GBT classifier:%s\" % model)\n#prediction_gb = model.transform(testing_df)\n#bc.evaluate(prediction_gb)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":100},{"cell_type":"code","source":["#var_val1 = [gb_best[gb_bestpipe.getParam('maxDepth')],gb_best[gb_bestpipe.getParam('minInstancesPerNode')],\n#            gb_best[gb_bestpipe.getParam('featureSubsetStrategy')],gb_best[gb_bestpipe.getParam('stepSize')]]\n\n#var_val1"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":101},{"cell_type":"markdown","source":["##### Best Model"],"metadata":{}},{"cell_type":"code","source":["gbt_best = GBTClassifier(featuresCol='cfeatures',labelCol='target_shares',maxDepth = 5 ,minInstancesPerNode=1,featureSubsetStrategy='all',stepSize=0.1)\ngbt_pipe_best  = Pipeline(stages=[v, gbt_best ])\ngbt_pipeline_best  = gbt_pipe_best.fit(training_df)\nbc = BinaryClassificationEvaluator(labelCol='target_shares')\nprediction_best  = gbt_pipeline_best.transform(testing_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":103},{"cell_type":"code","source":["print('The AUC Score: ',bc.evaluate(prediction_best))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">The AUC Score:  0.7219886675196485\n</div>"]}}],"execution_count":104},{"cell_type":"markdown","source":["##### Metrics"],"metadata":{}},{"cell_type":"code","source":["z = gbt_pipeline_best.transform(testing_df)\nevaluatorac = MulticlassClassificationEvaluator(labelCol='target_shares', predictionCol='prediction', metricName='accuracy')\naccuracy_gb = evaluatorac.evaluate(z)\nprint(\"Accuracy = %g\" % accuracy_gb)\nevaluator_f = MulticlassClassificationEvaluator(labelCol='target_shares', predictionCol='prediction', metricName='f1')\nf1 = evaluator_f.evaluate(z)\nprint(\"f1 = %g\" % f1)\nevaluator_re = MulticlassClassificationEvaluator(labelCol='target_shares', predictionCol='prediction', metricName='weightedRecall')\nrec = evaluator_re.evaluate(z)\nprint(\"Recall = %g\" % rec)\nevaluator_wp = MulticlassClassificationEvaluator(labelCol='target_shares', predictionCol='prediction', metricName='weightedPrecision')\npre = evaluator_wp.evaluate(z)\nprint(\"Precision = %g\" % pre)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy = 0.664554\nf1 = 0.664036\nRecall = 0.664554\nPrecision = 0.663888\n</div>"]}}],"execution_count":106},{"cell_type":"markdown","source":["##### ROC Curve"],"metadata":{}},{"cell_type":"code","source":["preds = z.select('target_shares','probability').rdd.\\\n        map(lambda row: (float(row['probability'][1]), float(row['target_shares']))).collect()\n\ny_score, y_true = zip(*preds)\nfpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label = 1)\n\nplt.figure(figsize=(10, 6))\nplt.scatter(fpr, tpr, linewidth=1, label='Best',color='green')\nplt.plot([0, 1], [0, 1],linestyle='--', label='Random',color='blue')                                 \nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16) \nplt.title('ROC for the Gradient Boosting Classifier')\nplt.legend()\nplt.grid(True)  \ndisplay()"],"metadata":{},"outputs":[],"execution_count":108},{"cell_type":"markdown","source":["### Random Forest Regression"],"metadata":{}},{"cell_type":"markdown","source":["##### *Base Model*"],"metadata":{}},{"cell_type":"code","source":["rf_rg = regression.RandomForestRegressor(featuresCol='cfeatures',labelCol='shares')\nrf_rgpipe = Pipeline(stages=[v, rf_rg])\nrf_rgpipe_fitted = rf_rgpipe.fit(training_df)\nrf_df = rf_rgpipe_fitted.transform(testing_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":111},{"cell_type":"markdown","source":["##### *Finding the RMSE*"],"metadata":{}},{"cell_type":"code","source":["rf_df.select('cfeatures','shares','prediction')\nevaluator = RegressionEvaluator(labelCol='shares',\n                                predictionCol='prediction',\n                                metricName='rmse')\n\nrmse = evaluator.evaluate(rf_df)\nprint('Root Mean Squared Error (RMSE) on test data = %g' % rmse)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Root Mean Squared Error (RMSE) on test data = 13277.6\n</div>"]}}],"execution_count":113},{"cell_type":"markdown","source":["##### *Grid search for Random forest regressor*"],"metadata":{}},{"cell_type":"code","source":["#paramgrid_lin = ParamGridBuilder().addGrid(lin.numTrees, [100,200,300])\\\n#                .addGrid(lin.featureSubsetStrategy, ['auto','log2']).addGrid(lin.maxDepth, [1,3,5]).build()\n#crossval_lin = CrossValidator(estimator=lin_pipeline,estimatorParamMaps=paramgrid_lin, \n#                              evaluator=RegressionEvaluator(labelCol='shares'), numFolds=3)\n#cvmodel_lin = crossval_lin.fit(training_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":115},{"cell_type":"code","source":["#bestmodel_lin = cvmodel_lin.bestModel.stages[-1]\n#bestParams_lin = bestmodel_lin.extractParamMap()\n\n#var_nam_lin = ['numTrees','featureSubsetStrategy','maxDepth']\n#var_val_lin = [bestParams_lin[bestmodel_lin.getParam('numTrees')],bestParams_lin[bestmodel_lin.getParam('featureSubsetStrategy')],\n#               bestParams_lin[bestmodel_lin.getParam('maxDepth')]]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":116},{"cell_type":"markdown","source":["##### Model is built using the best parameter values from grid search"],"metadata":{}},{"cell_type":"code","source":["lin_t = regression.RandomForestRegressor(numTrees = 200, featureSubsetStrategy = 'log2', maxDepth = 5,\n                                         featuresCol='cfeatures',labelCol='shares')\nlin_t_pipeline = Pipeline(stages=[v, lin_t])\nlin_t_fitted = lin_t_pipeline.fit(training_df)\nlin_t_df = lin_t_fitted.transform(testing_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":118},{"cell_type":"markdown","source":["##### Finding RMSE for best model"],"metadata":{}},{"cell_type":"code","source":["evaluator = RegressionEvaluator(labelCol='shares',\n                                predictionCol='prediction',\n                                metricName='rmse')\n\nrmse = evaluator.evaluate(lin_t_df)\nprint('Root Mean Squared Error (RMSE) on test data = %g' % rmse)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Root Mean Squared Error (RMSE) on test data = 12956\n</div>"]}}],"execution_count":120}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.4","nbconvert_exporter":"python","file_extension":".py"},"name":"bad akshay","notebookId":53551077807155},"nbformat":4,"nbformat_minor":0}
